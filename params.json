{
  "name": "Ocaml-prog-pats",
  "tagline": "OCaml Programming Patterns - random tricks, \"design patterns\", etc.",
  "body": "OCaml Programming Patterns\r\n==========================\r\n\r\n---------------------------------------------------------------------------\r\n\r\nPurpose\r\n-------\r\n\r\nThis package contains some random programming tricks, \"design patterns\",\r\nand other helpful or at least inspiring ideas of achieving a high level of\r\nabstraction in OCaml programs that I have come across over time.  Some may\r\ndemonstrate how to implement concepts of more or less theoretical interest\r\n(e.g. arrows, monads), others show more practical hints on how to structure\r\ncode to make it more reusable (e.g. abstract lexers, extensible ASTs).\r\n\r\nContents\r\n--------\r\n\r\nThe package currently contains the following:\r\n\r\n  * [Abstract Lexer](#abstract_lexer)\r\n  * [Extensible ASTs](#extensible_asts)\r\n  * [Arrows](#arrows)\r\n  * [Functor instantiation](#functor_instantiation)\r\n\r\n### Abstract Lexer\r\n\r\n#### Quick introduction to syntactic analysis\r\n\r\nThe first step in the process of compilation or interpretation of computer\r\nprograms or other formal languages is typically lexical and syntactic analysis,\r\nor in other terms:\r\n\r\n  1. Lexing\r\n  2. Parsing\r\n\r\nThe process of lexing transforms a stream of _characters_ (e.g. ANSI,\r\nUnicode, etc.) to a stream of _tokens_, thus providing a more accessible\r\nrepresentation of the elements in the input.  This step might, for example,\r\nidentify keywords, numbers, operators, etc.  The process of parsing assigns\r\na grammatical structure to these elements, thus grouping them in ways that\r\nallow us to interpret the input more easily.\r\n\r\n#### Purpose of the abstract lexer\r\n\r\nThe purpose of the _abstract lexer_ is to fully separate steps one and two\r\nabove when using `ocamllex` to generate lexers.\r\n\r\nProgrammers typically implement lexers such that they generate a token\r\nstream for a particular parser.  This is usually all they need so there is\r\nno problem with that.  But sometimes requirements change and we may want to\r\nuse different parsers with the same lexer.\r\n\r\nFor example, the requirement for one parser might be optimum efficiency.\r\nIt may not want to deal with comments in an input file and rather ignore those\r\nalready during lexing.  We may want to avoid having to implement grammar\r\nrules that take into account comment syntax in that case.  Other parsers,\r\nhowever, might want to keep comments, for example to pretty-print transformed\r\ninput without losing this valuable information.\r\n\r\nThe _abstract lexer_ achieves this separation by wrapping lexers generated by\r\n`ocamllex` into a functor that abstracts over the types of values (\"tokens\")\r\nreturned by the lexer.\r\n\r\nA lexer specification usually consists of several _rules_ (functions).\r\nThese functions take the current state of the lexer, which specifies the\r\nposition in the input stream, and try to match one ore more _patterns_\r\n(regular expressions) at the current location in the input stream.  If a\r\npattern matches, an associated action will be executed.\r\n\r\nInstead of returning a specific parser token from within an action, which\r\nwould be the usual thing to do, abstract lexers call a function in the\r\nfunctor argument and pass it whatever lexeme (or relevant part of a lexeme)\r\nthe lexer has just identified.  This function may then return a parser token\r\nfor whatever parser it is intended for.\r\n\r\nSometimes lexer rules may also call other lexer rules recursively.  In the\r\nabstract lexer design, however, we never call other rules explicitly.\r\nThere is hence no explicit recursion.  This is important, because some\r\nparsers may want to just let the lexer continue matching further input rather\r\nthan return a token, whereas others might want to see a token to relate it\r\ngrammatically to others.\r\n\r\n#### Example implementation\r\n\r\nThe `abstract_lexer` directory contains the following files:\r\n\r\n  * `lexer.mll`\r\n  * `lexers.ml`\r\n  * `main.ml`\r\n  * `test.dat`\r\n\r\nThe `ocamllex` file `lexer.mll` demonstrates how to wrap a lexer into a\r\nfunctor.  The signature of the functor argument is `Spec`.  This specification\r\nintroduces a module for each rule in the lexer (e.g. `Any_char`) containing\r\nan abstract type `t`.  All rule actions have to return the same type anyway,\r\nand here this type is completely abstract rather than a particular type of\r\nparser tokens.\r\n\r\nNow we introduce a function for each pattern action,\r\ne.g. `Any_char.handle_char`.  It has to take the current `lexbuf` as argument\r\nso that an instance of the lexer can extract additional lexeme information\r\n(e.g. location information if required), or to allow recursive calls to\r\nother lexer rules.  We may often want to also pass additional arguments,\r\ne.g. particular parts of the lexeme that we have already extracted.  This is\r\nuseful if, for example, we attach identifiers to sub-patterns in the lexer\r\nrule.\r\n\r\nThe functor in `lexer.mll` is introduced in the header part of the lexer\r\nspecification and closed in the trailer, thus wrapping the automatically\r\ngenerated lexer code into its body.\r\n\r\nAn example instance of this lexer is given in file `lexers.ml`.  It is called\r\n`Lexers.Alternating` and demonstrates how to specify recursive lexer rules.\r\nThis is achieved by making the module `Alternating` itself recursive.\r\n\r\nThe file `main.ml` will start lexing from standard input with rule\r\n`Lexers.Alternating.any_char`.  Valid example input can be found in\r\nfile `test.dat`.  You can compile and test the example by going to the\r\n`abstract_lexer` directory and executing:\r\n\r\n```sh\r\nocamlbuild main.native\r\n./main.native < test.dat\r\n```\r\n\r\n#### Fazit\r\n\r\nIt seems recommendable to write new lexers in an abstract style as demonstrated\r\nabove.  This will allow you to completely and cleanly separate the stages\r\nof lexical and syntactic analysis.  If, for example, future requirements\r\nask for a new parser, you won't have to pollute old parser specifications\r\nwith new tokens and dummy rules.\r\n\r\nThe performance impact of this abstraction will generally be neglible,\r\nassuming the lexer is well-written.  This requires that as much work as\r\npossible is assigned to the lexing engine rather than to pattern actions.\r\nE.g. rules containing a pattern that matches a single character and which\r\nare called recursively to handle input in this piece-wise fashion should be\r\nrewritten to match one complex pattern and perform one action only instead.\r\nThis will generally give a great boost to lexer performance, especially if\r\nit is abstract.\r\n\r\n### Extensible ASTs\r\n\r\nThis simple example shows how to implement extensible abstract syntax trees\r\n(ASTs).  It uses polymorphic variants to achieve open recursion and to easily\r\ncompose multiple recursive \"languages\".\r\n\r\nSee the file `ast.ml` in directory `extensible_ast`, which you can compile\r\nas follows:\r\n\r\n```sh\r\nocamlbuild ast.native\r\n```\r\n\r\n### Arrows\r\n\r\nThis project in directory `arrows` mostly translates the Haskell-code\r\npresented in the following paper to OCaml:\r\n\r\n    Generalising Monads to Arrows\r\n    John Hughes\r\n    Science of Computer Programming 37, pp67-111, May 2000\r\n\r\nThe project contains the following files:\r\n\r\n  * `arrow.mli` and `arrow.ml`\r\n  * `arr.ml`\r\n\r\nThe module `Arrow` has a fully documented API and provides several simple\r\nimplementations for arrows, which can be extended to arrows with more\r\nconvenience functions.  The signature of simple arrows specifies the type\r\nof arrows and the following functions:\r\n\r\n  * `arr` - creates arrows from ordinary functions\r\n  * `>>>` - the arrow composition operator\r\n  * `app` - arrow application\r\n  * `run` - a function to \"chase arrows\"\r\n\r\nThe `arr`-function and composition operator are at the core of arrows, but\r\nare not sufficient to give them the same power as e.g. monads.  Adding arrow\r\napplication restores this power and allows us to enrich them with numerous\r\nother functions that provide useful programming idioms, e.g. for dealing\r\nwith tuples or choice.  Please refer to the above-mentioned paper for details.\r\n\r\nThe simplest arrow implementation in module `SimpleArrow` just uses ordinary\r\nfunctions as representation of arrows.  It suffers from stack overflows\r\nif arrow composition is nested too deeply.  The module `SimpleContArrow`\r\nfixes this problem by representing arrows with continuations.  Module\r\n`SimpleDataContArrow` uses sum tags for representing the structure of arrows\r\nand their compositions.  It also uses continuations to avoid stack overflows.\r\n\r\nThe functor `MkArrow` takes a simple arrow and enriches it with more\r\nfunctions as described in John Hughes' paper.  Module `Arrow` finally also\r\nimplements monads by showing how we can obtain one from an arrow supporting\r\narrow application and vice versa, thus proving their equivalence in terms\r\nof expressive power.\r\n\r\n### Functor instantiation\r\n\r\nThe example in directory `functor_inst` demonstrates how to use the Camlp4\r\npreprocessor together with its standard `Camlp4MacroParser` to instantiate\r\nmodule functors at compile time.  This only works within modules, not across\r\nmodule files, for obvious reasons.  Instantiating functors at compile time\r\ncan yield substantial performance improvements.\r\n\r\nYou can build the fully documented code using:\r\n\r\n```sh\r\nocamlbuild -use-ocamlfind functor_inst.native\r\n```\r\n\r\n---------------------------------------------------------------------------\r\n\r\nContact Information and Contributing\r\n------------------------------------\r\n\r\nIn the case of bugs, feature requests, contributions and similar, you can\r\ncontact me here: <markus.mottl@gmail.com>\r\n\r\nUp-to-date information concerning this tool should be available at:\r\n<https://mmottl.github.io/ocaml-prog-pats>\r\n\r\nEnjoy!\r\n\r\nMarkus Mottl on November 29, 2012\r\n",
  "google": "",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}